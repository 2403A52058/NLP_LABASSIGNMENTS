{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7l4wtX4ui8KeuU5Y74N7j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403A52058/NLP_LABASSIGNMENTS/blob/main/NLP_LAB(07)_2403A52058.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Required Libraries"
      ],
      "metadata": {
        "id": "oMnI6TyoPms1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "We4s_h9RJueZ"
      },
      "outputs": [],
      "source": [
        "# Import basic libraries\n",
        "import numpy as np          # Numerical computations\n",
        "import pandas as pd         # Dataset handling\n",
        "import re                   # Text cleaning\n",
        "\n",
        "# Import NLP libraries\n",
        "import nltk\n",
        "from nltk.corpus import stopwords     # Stopword removal\n",
        "from nltk.tokenize import word_tokenize  # Tokenization\n",
        "from nltk.stem import WordNetLemmatizer  # Lemmatization\n",
        "from nltk.corpus import wordnet       # Semantic similarity\n",
        "\n",
        "# Import ML libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDF\n",
        "from sklearn.metrics.pairwise import cosine_similarity       # Cosine similarity\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download NLTK Resources"
      ],
      "metadata": {
        "id": "-TNVs0TnPp1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required NLTK datasets\n",
        "nltk.download('punkt')       # Tokenizer\n",
        "nltk.download('stopwords')   # Stopwords list\n",
        "nltk.download('wordnet')     # WordNet database\n",
        "nltk.download('punkt_tab')   # Required for tokenization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zADMY307Ptg0",
        "outputId": "e46e337b-9979-412c-8664-019304e0ee96"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Dataset"
      ],
      "metadata": {
        "id": "5s-oKiQjPx-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataset with multiple topics\n",
        "documents = [\n",
        "    # Sports\n",
        "    \"The football team won the championship\",\n",
        "    \"Cricket players trained hard for the match\",\n",
        "    \"The athlete broke the world record\",\n",
        "    \"The coach discussed game strategy\",\n",
        "    \"The tournament attracted many fans\",\n",
        "\n",
        "    # Politics\n",
        "    \"The government passed a new law\",\n",
        "    \"Elections were held across the country\",\n",
        "    \"The president addressed the nation\",\n",
        "    \"Political parties debated policies\",\n",
        "    \"The parliament session was intense\",\n",
        "\n",
        "    # Health\n",
        "    \"Doctors recommend regular exercise\",\n",
        "    \"The hospital treated many patients\",\n",
        "    \"Healthy diet improves immunity\",\n",
        "    \"The physician prescribed medicine\",\n",
        "    \"Mental health awareness is important\",\n",
        "\n",
        "    # Technology\n",
        "    \"Artificial intelligence is transforming industries\",\n",
        "    \"The smartphone has advanced features\",\n",
        "    \"Cybersecurity protects digital data\",\n",
        "    \"Software development requires coding skills\",\n",
        "    \"Machine learning improves predictions\"\n",
        "]\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame({\"Document\": documents})\n",
        "\n",
        "# Display dataset sample\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "iRPIO8wmPxuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Preprocessing Function"
      ],
      "metadata": {
        "id": "_qsyfJaNP6TD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load stopwords and initialize lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()                       # Convert to lowercase\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)      # Remove punctuation and numbers\n",
        "    tokens = word_tokenize(text)              # Tokenize text\n",
        "    tokens = [w for w in tokens if w not in stop_words]  # Remove stopwords\n",
        "    tokens = [lemmatizer.lemmatize(w) for w in tokens]   # Lemmatize words\n",
        "    return \" \".join(tokens)                   # Join tokens\n"
      ],
      "metadata": {
        "id": "EWJFwUITQLQb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply Preprocessing"
      ],
      "metadata": {
        "id": "_yZ2eun2QR7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing to all documents\n",
        "df[\"Cleaned_Document\"] = df[\"Document\"].apply(preprocess_text)\n",
        "\n",
        "# Display cleaned text\n",
        "df[[\"Document\", \"Cleaned_Document\"]].head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YjUDHOOnQ0TU",
        "outputId": "c2bcae11-4612-4252-89da-3ede634c20d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     Document  \\\n",
              "0      The football team won the championship   \n",
              "1  Cricket players trained hard for the match   \n",
              "2          The athlete broke the world record   \n",
              "3           The coach discussed game strategy   \n",
              "4          The tournament attracted many fans   \n",
              "\n",
              "                    Cleaned_Document  \n",
              "0         football team championship  \n",
              "1  cricket player trained hard match  \n",
              "2         athlete broke world record  \n",
              "3      coach discussed game strategy  \n",
              "4      tournament attracted many fan  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4dea4ad9-b35d-4ca5-ab40-a7ef1c3cf533\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Cleaned_Document</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The football team won the championship</td>\n",
              "      <td>football team championship</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cricket players trained hard for the match</td>\n",
              "      <td>cricket player trained hard match</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The athlete broke the world record</td>\n",
              "      <td>athlete broke world record</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The coach discussed game strategy</td>\n",
              "      <td>coach discussed game strategy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The tournament attracted many fans</td>\n",
              "      <td>tournament attracted many fan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4dea4ad9-b35d-4ca5-ab40-a7ef1c3cf533')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4dea4ad9-b35d-4ca5-ab40-a7ef1c3cf533 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4dea4ad9-b35d-4ca5-ab40-a7ef1c3cf533');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[[\\\"Document\\\", \\\"Cleaned_Document\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Cricket players trained hard for the match\",\n          \"The tournament attracted many fans\",\n          \"The athlete broke the world record\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cleaned_Document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"cricket player trained hard match\",\n          \"tournament attracted many fan\",\n          \"athlete broke world record\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Representation"
      ],
      "metadata": {
        "id": "w_ZH5x54RCW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Convert text to numerical form\n",
        "tfidf_matrix = vectorizer.fit_transform(df[\"Cleaned_Document\"])\n",
        "\n",
        "# Display shape of TF-IDF matrix\n",
        "tfidf_matrix.shape   # (documents, unique words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou3xT_LfRFkU",
        "outputId": "e14058f3-bf46-48d9-d4ee-d5451812490c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 75)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine Similarity Calculation"
      ],
      "metadata": {
        "id": "6cpVgbc8RIes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute cosine similarity between all document pairs\n",
        "cosine_sim = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "# Sample cosine similarity outputs\n",
        "print(\"Doc 0 vs Doc 1:\", cosine_sim[0][1])     # Sports vs Sports\n",
        "print(\"Doc 0 vs Doc 10:\", cosine_sim[0][10])   # Sports vs Health\n",
        "print(\"Doc 15 vs Doc 19:\", cosine_sim[15][19]) # Technology vs Technology\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbf3QHCGRI2U",
        "outputId": "7b28a18d-951f-48d3-b332-e9ca4d7ca1f6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doc 0 vs Doc 1: 0.0\n",
            "Doc 0 vs Doc 10: 0.0\n",
            "Doc 15 vs Doc 19: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jaccard Similarity Function"
      ],
      "metadata": {
        "id": "DqHRj_nnRYNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jaccard similarity function\n",
        "def jaccard_similarity(doc1, doc2):\n",
        "    set1 = set(doc1.split())          # Convert document 1 to word set\n",
        "    set2 = set(doc2.split())          # Convert document 2 to word set\n",
        "    return len(set1 & set2) / len(set1 | set2)  # Jaccard formula\n"
      ],
      "metadata": {
        "id": "4d2-C_kLRRYU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jaccard Similarity Output"
      ],
      "metadata": {
        "id": "bvUqc3vQReY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sample Jaccard similarity scores\n",
        "print(\"Doc 0 vs Doc 1:\", jaccard_similarity(df[\"Cleaned_Document\"][0],\n",
        "                                            df[\"Cleaned_Document\"][1]))\n",
        "print(\"Doc 0 vs Doc 10:\", jaccard_similarity(df[\"Cleaned_Document\"][0],\n",
        "                                             df[\"Cleaned_Document\"][10]))\n",
        "print(\"Doc 12 vs Doc 14:\", jaccard_similarity(df[\"Cleaned_Document\"][12],\n",
        "                                              df[\"Cleaned_Document\"][14]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5mwTmr9RfAz",
        "outputId": "9a8d26ea-312a-40a8-a372-f6badfe55fc6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doc 0 vs Doc 1: 0.0\n",
            "Doc 0 vs Doc 10: 0.0\n",
            "Doc 12 vs Doc 14: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet Semantic Similarity Function"
      ],
      "metadata": {
        "id": "nrEhHF2HRm5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WordNet similarity using Wu-Palmer method\n",
        "def wordnet_similarity(word1, word2):\n",
        "    syn1 = wordnet.synsets(word1)     # Get synsets for word1\n",
        "    syn2 = wordnet.synsets(word2)     # Get synsets for word2\n",
        "    if not syn1 or not syn2:\n",
        "        return 0                      # No similarity if word not found\n",
        "    return syn1[0].wup_similarity(syn2[0]) or 0\n"
      ],
      "metadata": {
        "id": "mYfzxrkyRniE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet Similarity Output"
      ],
      "metadata": {
        "id": "xmgvhIJYRu6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display semantic similarity for word pairs\n",
        "print(\"doctor - physician:\", wordnet_similarity(\"doctor\", \"physician\"))\n",
        "print(\"football - sport:\", wordnet_similarity(\"football\", \"sport\"))\n",
        "print(\"government - politics:\", wordnet_similarity(\"government\", \"politics\"))\n",
        "print(\"smartphone - device:\", wordnet_similarity(\"smartphone\", \"device\"))\n",
        "print(\"exercise - health:\", wordnet_similarity(\"exercise\", \"health\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH0UvAoqRy4E",
        "outputId": "3fd5c5c8-8bb2-46e2-86fb-48d723fb5097"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "doctor - physician: 1.0\n",
            "football - sport: 0.8888888888888888\n",
            "government - politics: 0.3333333333333333\n",
            "smartphone - device: 0\n",
            "exercise - health: 0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K3j4wG_NR2Zk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}